{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Advanced Stats & Four Factors EDA Pipeline\n",
    "\n",
    "## Objective\n",
    "Ingest game data, calculate rolling advanced metrics, and visualize key predictors for win margins/spreads. This notebook focuses on NBA-specific metrics like Variance, Energy, and Schedule Spots.\n",
    "\n",
    "## Metrics of Interest\n",
    "1. **Net Rating (NetRtg)**: Point differential per 100 possessions.\n",
    "2. **Four Factors**: eFG%, TOV%, OREB%, FT Rate.\n",
    "3. **Schedule Spots**: SEGABABA (Second Game of Back-to-Back), 3-in-4, Altitude Advantage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240534f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not determine nba_api version\n"
     ]
    }
   ],
   "source": [
    "# 1. Environment Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from requests.exceptions import RequestException\n",
    "from nba_api.stats.endpoints import leaguegamefinder, boxscoreadvancedv2, boxscorefourfactorsv2, boxscoretraditionalv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "# NBA.com blocks scripts without browser-like headers; set once and reuse everywhere.\n",
    "NBA_API_HEADERS = {\n",
    "    'Host': 'stats.nba.com',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/117.0',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Referer': 'https://www.nba.com/',\n",
    "    'Origin': 'https://www.nba.com',\n",
    "    'Connection': 'keep-alive',\n",
    "    'x-nba-stats-origin': 'stats',\n",
    "    'x-nba-stats-token': 'true'\n",
    "}\n",
    "REQUEST_TIMEOUT = 100  # generous timeout to avoid hanging on slow responses\n",
    "\n",
    "# Check nba_api version\n",
    "try:\n",
    "    import nba_api\n",
    "    print(f\"nba_api version: {nba_api.__version__}\")\n",
    "except:\n",
    "    print(\"Could not determine nba_api version\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd84b2",
   "metadata": {},
   "source": [
    "## 2. Data Ingestion\n",
    "\n",
    "We will fetch the game schedule and then loop through games to get advanced stats and four factors. **Updated to fetch 10 seasons.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "366d616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching schedule for seasons: ['2015-16', '2016-17', '2017-18', '2018-19', '2019-20', '2020-21', '2021-22', '2022-23', '2023-24', '2024-25', '2025-26']\n",
      "Fetching 2015-16...\n",
      "Fetching 2016-17...\n",
      "Fetching 2017-18...\n",
      "Fetching 2018-19...\n",
      "Fetching 2019-20...\n",
      "Fetching 2020-21...\n",
      "Fetching 2021-22...\n",
      "Fetching 2022-23...\n",
      "Fetching 2023-24...\n",
      "Fetching 2024-25...\n",
      "Fetching 2025-26...\n",
      "Fetched 24524 games across 11 seasons.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON_ID</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>WL</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FG3_PCT</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT_PCT</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-16</td>\n",
       "      <td>1610612750</td>\n",
       "      <td>MIN</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>0021501226</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>MIN vs. NOP</td>\n",
       "      <td>W</td>\n",
       "      <td>240</td>\n",
       "      <td>144</td>\n",
       "      <td>56</td>\n",
       "      <td>86</td>\n",
       "      <td>0.651</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>0.464</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>0.826</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-16</td>\n",
       "      <td>1610612759</td>\n",
       "      <td>SAS</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>0021501223</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>SAS @ DAL</td>\n",
       "      <td>W</td>\n",
       "      <td>240</td>\n",
       "      <td>96</td>\n",
       "      <td>35</td>\n",
       "      <td>74</td>\n",
       "      <td>0.473</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.261</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>0.769</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>42</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-16</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>0021501223</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>DAL vs. SAS</td>\n",
       "      <td>L</td>\n",
       "      <td>240</td>\n",
       "      <td>91</td>\n",
       "      <td>31</td>\n",
       "      <td>77</td>\n",
       "      <td>0.403</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>0.308</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>0.810</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-16</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>GSW</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>0021501227</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>GSW vs. MEM</td>\n",
       "      <td>W</td>\n",
       "      <td>240</td>\n",
       "      <td>125</td>\n",
       "      <td>46</td>\n",
       "      <td>87</td>\n",
       "      <td>0.529</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>0.426</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0.813</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-16</td>\n",
       "      <td>1610612758</td>\n",
       "      <td>SAC</td>\n",
       "      <td>Sacramento Kings</td>\n",
       "      <td>0021501224</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>SAC @ HOU</td>\n",
       "      <td>L</td>\n",
       "      <td>238</td>\n",
       "      <td>81</td>\n",
       "      <td>32</td>\n",
       "      <td>96</td>\n",
       "      <td>0.333</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "      <td>0.297</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0.462</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>49</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>-35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SEASON_ID     TEAM_ID TEAM_ABBREVIATION               TEAM_NAME     GAME_ID  \\\n",
       "0   2015-16  1610612750               MIN  Minnesota Timberwolves  0021501226   \n",
       "1   2015-16  1610612759               SAS       San Antonio Spurs  0021501223   \n",
       "2   2015-16  1610612742               DAL        Dallas Mavericks  0021501223   \n",
       "3   2015-16  1610612744               GSW   Golden State Warriors  0021501227   \n",
       "4   2015-16  1610612758               SAC        Sacramento Kings  0021501224   \n",
       "\n",
       "    GAME_DATE      MATCHUP WL  MIN  PTS  FGM  FGA  FG_PCT  FG3M  FG3A  \\\n",
       "0  2016-04-13  MIN vs. NOP  W  240  144   56   86   0.651    13    28   \n",
       "1  2016-04-13    SAS @ DAL  W  240   96   35   74   0.473     6    23   \n",
       "2  2016-04-13  DAL vs. SAS  L  240   91   31   77   0.403    12    39   \n",
       "3  2016-04-13  GSW vs. MEM  W  240  125   46   87   0.529    20    47   \n",
       "4  2016-04-13    SAC @ HOU  L  238   81   32   96   0.333    11    37   \n",
       "\n",
       "   FG3_PCT  FTM  FTA  FT_PCT  OREB  DREB  REB  AST  STL  BLK  TOV  PF  \\\n",
       "0    0.464   19   23   0.826     5    38   43   41   14    8   13  20   \n",
       "1    0.261   20   26   0.769     8    34   42   24    8    3   14  19   \n",
       "2    0.308   17   21   0.810    11    30   41   20    8    2   12  23   \n",
       "3    0.426   13   16   0.813    12    39   51   35    7    7   17  14   \n",
       "4    0.297    6   13   0.462    15    34   49   21   11    4   17  17   \n",
       "\n",
       "   PLUS_MINUS  \n",
       "0        35.0  \n",
       "1         5.0  \n",
       "2        -5.0  \n",
       "3        21.0  \n",
       "4       -35.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch Game Schedule for multiple seasons\n",
    "\n",
    "def fetch_schedule(season='2024-25', season_type='Regular Season', retries=3, retry_delay=2.0):\n",
    "    \"\"\"Fetch a season schedule with headers/timeout and simple retries for timeouts/blocks.\"\"\"\n",
    "    last_err = None\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            gamefinder = leaguegamefinder.LeagueGameFinder(\n",
    "                season_nullable=season,\n",
    "                league_id_nullable='00',\n",
    "                season_type_nullable=season_type,\n",
    "                headers=NBA_API_HEADERS,\n",
    "                timeout=REQUEST_TIMEOUT\n",
    "            )\n",
    "            games = gamefinder.get_data_frames()[0]\n",
    "            return games\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            print(f\"Attempt {attempt}/{retries} failed for {season}: {e}\")\n",
    "            time.sleep(retry_delay * attempt)\n",
    "    raise last_err\n",
    "\n",
    "def fetch_all_seasons_schedule(start_year=2015, end_year=2025):\n",
    "    all_games = []\n",
    "    seasons = [f\"{year}-{str(year+1)[-2:]}\" for year in range(start_year, end_year + 1)]\n",
    "    error_log = []\n",
    "    \n",
    "    print(f\"Fetching schedule for seasons: {seasons}\")\n",
    "    \n",
    "    for season in seasons:\n",
    "        print(f\"Fetching {season}...\")\n",
    "        try:\n",
    "            games = fetch_schedule(season=season)\n",
    "            games['SEASON_ID'] = season  # Ensure we track the season\n",
    "            all_games.append(games)\n",
    "            time.sleep(1.5)  # Respect rate limits and avoid blocks\n",
    "        except Exception as e:\n",
    "            msg = str(e)\n",
    "            print(f\"Error fetching {season}: {msg}\")\n",
    "            error_log.append((season, msg))\n",
    "            # Small pause before next season to avoid cascading timeouts\n",
    "            time.sleep(2.5)\n",
    "            continue\n",
    "            \n",
    "    if not all_games:\n",
    "        raise RuntimeError(\"No schedules fetched; check network/API access and headers.\")\n",
    "    \n",
    "    if error_log:\n",
    "        print(f\"Completed with {len(error_log)} season fetch errors: {error_log}\")\n",
    "    \n",
    "    return pd.concat(all_games, ignore_index=True)\n",
    "\n",
    "schedule_df = fetch_all_seasons_schedule()\n",
    "print(f\"Fetched {len(schedule_df)} games across {len(schedule_df['SEASON_ID'].unique())} seasons.\")\n",
    "schedule_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59f8558d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NBA API DIAGNOSTICS\n",
      "============================================================\n",
      "\n",
      "1. Testing with recent game ID: 0022500075\n",
      "   Game Date: 2025-11-28\n",
      "   Matchup: PHX @ OKC\n",
      "\n",
      "2. Testing BoxScoreAdvancedV2...\n",
      "   \u2717 KeyError caught: 'resultSet'\n",
      "   Error message: 'resultSet'\n",
      "\n",
      "   DIAGNOSIS: The error occurs when the library tries to access 'resultSet'\n",
      "   This suggests the API response structure doesn't match what the library expects\n",
      "\n",
      "3. Testing BoxScoreFourFactorsV2...\n",
      "   \u2717 KeyError: 'resultSet'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ff_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 110\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     ff_test = \u001b[43mboxscorefourfactorsv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBoxScoreFourFactorsV2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_game_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# Inspect raw response\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python314\\Lib\\site-packages\\nba_api\\stats\\endpoints\\boxscorefourfactorsv2.py:84\u001b[39m, in \u001b[36mBoxScoreFourFactorsV2.__init__\u001b[39m\u001b[34m(self, game_id, end_period, end_range, range_type, start_period, start_range, proxy, headers, timeout, get_request)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_request:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python314\\Lib\\site-packages\\nba_api\\stats\\endpoints\\boxscorefourfactorsv2.py:94\u001b[39m, in \u001b[36mBoxScoreFourFactorsV2.get_request\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28mself\u001b[39m.nba_response = NBAStatsHTTP().send_api_request(\n\u001b[32m     88\u001b[39m     endpoint=\u001b[38;5;28mself\u001b[39m.endpoint,\n\u001b[32m     89\u001b[39m     parameters=\u001b[38;5;28mself\u001b[39m.parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m     92\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.timeout,\n\u001b[32m     93\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python314\\Lib\\site-packages\\nba_api\\stats\\endpoints\\boxscorefourfactorsv2.py:97\u001b[39m, in \u001b[36mBoxScoreFourFactorsV2.load_response\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_response\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     data_sets = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnba_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_data_sets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mself\u001b[39m.data_sets = [\n\u001b[32m     99\u001b[39m         Endpoint.DataSet(data=data_set)\n\u001b[32m    100\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m data_set_name, data_set \u001b[38;5;129;01min\u001b[39;00m data_sets.items()\n\u001b[32m    101\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python314\\Lib\\site-packages\\nba_api\\stats\\library\\http.py:134\u001b[39m, in \u001b[36mNBAStatsResponse.get_data_sets\u001b[39m\u001b[34m(self, endpoint)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     results = \u001b[43mraw_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresultSet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[31mKeyError\u001b[39m: 'resultSet'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 135\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ke:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   \u2717 KeyError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mke\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mff_test\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mget_dict\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    136\u001b[39m         response_dict = ff_test.get_dict()\n\u001b[32m    137\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Response structure: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(response_dict.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'ff_test' is not defined"
     ]
    }
   ],
   "source": [
    "# DIAGNOSTIC: Inspect raw API response to understand the issue\n",
    "print(\"=\" * 60)\n",
    "print(\"NBA API DIAGNOSTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if schedule_df exists\n",
    "if 'schedule_df' not in globals() or schedule_df is None or len(schedule_df) == 0:\n",
    "    print(\"ERROR: schedule_df not found or empty. Please run the schedule fetch cell first.\")\n",
    "else:\n",
    "    # Get finished games from schedule_df\n",
    "    finished_games_check = schedule_df[schedule_df['WL'].notna()]['GAME_ID'].unique()\n",
    "    \n",
    "    if len(finished_games_check) > 0:\n",
    "    # Get the most recent game IDs (likely from later seasons)\n",
    "        recent_games = schedule_df[schedule_df['WL'].notna()].sort_values('GAME_DATE', ascending=False)\n",
    "    if len(recent_games) > 0:\n",
    "        test_game_id = str(recent_games.iloc[0]['GAME_ID'])\n",
    "        print(f\"\\n1. Testing with recent game ID: {test_game_id}\")\n",
    "        print(f\"   Game Date: {recent_games.iloc[0]['GAME_DATE']}\")\n",
    "        print(f\"   Matchup: {recent_games.iloc[0]['MATCHUP']}\")\n",
    "        \n",
    "        # Test Advanced Stats API\n",
    "        print(f\"\\n2. Testing BoxScoreAdvancedV2...\")\n",
    "        adv_test = None\n",
    "        try:\n",
    "            adv_test = boxscoreadvancedv2.BoxScoreAdvancedV2(game_id=test_game_id, headers=NBA_API_HEADERS, timeout=REQUEST_TIMEOUT)\n",
    "            \n",
    "            # Check API endpoint and parameters\n",
    "            print(\"   Checking API endpoint...\")\n",
    "            if hasattr(adv_test, 'endpoint'):\n",
    "                print(f\"   Endpoint: {adv_test.endpoint}\")\n",
    "            if hasattr(adv_test, 'parameters'):\n",
    "                print(f\"   Parameters: {adv_test.parameters}\")\n",
    "            if hasattr(adv_test, 'url'):\n",
    "                print(f\"   URL: {adv_test.url}\")\n",
    "            \n",
    "            # CRITICAL: Inspect raw response BEFORE calling get_data_frames()\n",
    "            print(\"   Inspecting raw API response (BEFORE get_data_frames)...\")\n",
    "            if hasattr(adv_test, 'get_dict'):\n",
    "                try:\n",
    "                    response_dict = adv_test.get_dict()\n",
    "                    print(f\"   \u2713 Successfully got response dictionary\")\n",
    "                    print(f\"   Response top-level keys: {list(response_dict.keys())}\")\n",
    "                    \n",
    "                    # Check for resultSets (plural) vs resultSet (singular)\n",
    "                    if 'resultSets' in response_dict:\n",
    "                        print(f\"   \u2713 Found 'resultSets' key (plural)\")\n",
    "                        print(f\"   Number of result sets: {len(response_dict['resultSets'])}\")\n",
    "                        for i, rs in enumerate(response_dict['resultSets']):\n",
    "                            print(f\"   ResultSet {i}: keys = {list(rs.keys()) if isinstance(rs, dict) else 'N/A'}\")\n",
    "                            if isinstance(rs, dict) and 'name' in rs:\n",
    "                                print(f\"     Name: {rs['name']}\")\n",
    "                            if isinstance(rs, dict) and 'rowSet' in rs:\n",
    "                                print(f\"     Rows: {len(rs['rowSet'])}\")\n",
    "                    elif 'resultSet' in response_dict:\n",
    "                        print(f\"   \u26a0 Found 'resultSet' key (singular, not plural)\")\n",
    "                        print(f\"   This might be the issue - API expects 'resultSets'\")\n",
    "                    else:\n",
    "                        print(f\"   \u2717 Neither 'resultSets' nor 'resultSet' found\")\n",
    "                        print(f\"   Full response keys: {list(response_dict.keys())}\")\n",
    "                        # Print a sample of the response\n",
    "                        import json\n",
    "                        print(f\"   Response sample: {json.dumps({k: str(v)[:100] for k, v in list(response_dict.items())[:3]}, indent=2)}\")\n",
    "                except Exception as dict_err:\n",
    "                    print(f\"   \u2717 Error getting dict: {dict_err}\")\n",
    "            \n",
    "            # Now try to get dataframes (this is where the error occurs)\n",
    "            print(\"\\n   Attempting to get dataframes (this may fail)...\")\n",
    "            adv_test_frames = adv_test.get_data_frames()\n",
    "            print(f\"   \u2713 Success! Got {len(adv_test_frames)} dataframes\")\n",
    "            if len(adv_test_frames) > 0:\n",
    "                print(f\"   First dataframe shape: {adv_test_frames[0].shape}\")\n",
    "                print(f\"   Columns: {list(adv_test_frames[0].columns)[:10]}...\")\n",
    "                \n",
    "        except KeyError as ke:\n",
    "            print(f\"   \u2717 KeyError caught: {ke}\")\n",
    "            print(f\"   Error message: {str(ke)}\")\n",
    "            if adv_test is not None:\n",
    "                # Try to inspect the response even after error\n",
    "                print(\"   Attempting to inspect response after error...\")\n",
    "                try:\n",
    "                    if hasattr(adv_test, 'get_dict'):\n",
    "                        response_dict = adv_test.get_dict()\n",
    "                        print(f\"   Response keys: {list(response_dict.keys())}\")\n",
    "                        # Check what's actually in the response\n",
    "                        if 'resultSets' in response_dict:\n",
    "                            print(f\"   \u2713 'resultSets' exists in response!\")\n",
    "                        elif 'resultSet' in response_dict:\n",
    "                            print(f\"   \u26a0 'resultSet' exists (singular) but library expects 'resultSets'\")\n",
    "                        else:\n",
    "                            print(f\"   \u2717 No resultSets/resultSet found\")\n",
    "                            print(f\"   Available keys: {list(response_dict.keys())}\")\n",
    "                except Exception as inspect_err:\n",
    "                    print(f\"   Could not inspect: {inspect_err}\")\n",
    "            \n",
    "            # Check if this is a known issue with the library\n",
    "            import traceback\n",
    "            tb = traceback.format_exc()\n",
    "            if 'resultSet' in tb:\n",
    "                print(f\"\\n   DIAGNOSIS: The error occurs when the library tries to access 'resultSet'\")\n",
    "                print(f\"   This suggests the API response structure doesn't match what the library expects\")\n",
    "        except Exception as e:\n",
    "            print(f\"   \u2717 Error: {type(e).__name__}: {e}\")\n",
    "            import traceback\n",
    "            print(f\"   Traceback (first 500 chars):\\n{traceback.format_exc()[:500]}\")\n",
    "        \n",
    "        # Test Four Factors API\n",
    "        print(f\"\\n3. Testing BoxScoreFourFactorsV2...\")\n",
    "        try:\n",
    "            ff_test = boxscorefourfactorsv2.BoxScoreFourFactorsV2(game_id=test_game_id, headers=NBA_API_HEADERS, timeout=REQUEST_TIMEOUT)\n",
    "            \n",
    "            # Inspect raw response\n",
    "            print(\"   Inspecting raw API response...\")\n",
    "            if hasattr(ff_test, 'get_dict'):\n",
    "                response_dict = ff_test.get_dict()\n",
    "                print(f\"   Response keys: {list(response_dict.keys())}\")\n",
    "                \n",
    "                if 'resultSets' in response_dict:\n",
    "                    print(f\"   \u2713 Found 'resultSets' key\")\n",
    "                    print(f\"   Number of result sets: {len(response_dict['resultSets'])}\")\n",
    "                else:\n",
    "                    print(f\"   \u2717 'resultSets' key NOT found\")\n",
    "                    print(f\"   Full response structure: {response_dict}\")\n",
    "            \n",
    "            # Try to get dataframes\n",
    "            print(\"   Attempting to get dataframes...\")\n",
    "            ff_test_frames = ff_test.get_data_frames()\n",
    "            print(f\"   \u2713 Success! Got {len(ff_test_frames)} dataframes\")\n",
    "            if len(ff_test_frames) > 0:\n",
    "                print(f\"   First dataframe shape: {ff_test_frames[0].shape}\")\n",
    "                print(f\"   Columns: {list(ff_test_frames[0].columns)[:10]}...\")\n",
    "                \n",
    "        except KeyError as ke:\n",
    "            print(f\"   \u2717 KeyError: {ke}\")\n",
    "            if hasattr(ff_test, 'get_dict'):\n",
    "                response_dict = ff_test.get_dict()\n",
    "                print(f\"   Response structure: {list(response_dict.keys())}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   \u2717 Error: {type(e).__name__}: {e}\")\n",
    "        \n",
    "        # Try alternative: Check if game exists using traditional boxscore (simpler endpoint)\n",
    "        print(f\"\\n4. Verifying game exists with traditional boxscore...\")\n",
    "        try:\n",
    "            trad_test = boxscoretraditionalv2.BoxScoreTraditionalV2(game_id=test_game_id, headers=NBA_API_HEADERS, timeout=REQUEST_TIMEOUT)\n",
    "            trad_frames = trad_test.get_data_frames()\n",
    "            print(f\"   \u2713 Traditional boxscore works! Got {len(trad_frames)} dataframes\")\n",
    "            if len(trad_frames) > 0:\n",
    "                print(f\"   First dataframe shape: {trad_frames[0].shape}\")\n",
    "                print(f\"   This confirms the game ID is valid\")\n",
    "        except Exception as e:\n",
    "            print(f\"   \u2717 Traditional boxscore also failed: {e}\")\n",
    "            print(f\"   This suggests the game ID might be invalid or game doesn't exist\")\n",
    "        \n",
    "        # Try alternative: Check if game_id needs different format\n",
    "        print(f\"\\n5. Testing alternative game ID formats...\")\n",
    "        # Try without leading zeros (if it's numeric)\n",
    "        try:\n",
    "            game_id_int = int(test_game_id)\n",
    "            print(f\"   Trying as integer: {game_id_int}\")\n",
    "            adv_test2 = boxscoreadvancedv2.BoxScoreAdvancedV2(game_id=game_id_int, headers=NBA_API_HEADERS, timeout=REQUEST_TIMEOUT)\n",
    "            adv_test2_frames = adv_test2.get_data_frames()\n",
    "            print(f\"   \u2713 Integer format works! Got {len(adv_test2_frames)} dataframes\")\n",
    "        except Exception as e:\n",
    "            print(f\"   \u2717 Integer format failed: {e}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "    else:\n",
    "        print(\"No finished games found to test with\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9168d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for finished games only to avoid errors\n",
    "finished_games = schedule_df[schedule_df['WL'].notna()]['GAME_ID'].unique()\n",
    "print(f\"Processing {len(finished_games)} finished games...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ccdbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_game_details(game_ids, schedule_df=None, max_games=50, start_from_recent=True):\n",
    "    advanced_list = []\n",
    "    four_factors_list = []\n",
    "    \n",
    "    # Limit for testing - remove [:max_games] for full run\n",
    "    # WARNING: Fetching 10 seasons of data will take HOURS.\n",
    "    # Recommended: Run in batches or parallelize if possible (but API limits prevent parallel).\n",
    "    \n",
    "    # Optionally sort by date (newest first) to test with games more likely to have stats\n",
    "    if start_from_recent and schedule_df is not None:\n",
    "        # Create a mapping of game_id to date for sorting\n",
    "        game_dates = schedule_df.set_index('GAME_ID')['GAME_DATE'].to_dict()\n",
    "        game_ids_sorted = sorted(game_ids, key=lambda x: game_dates.get(x, ''), reverse=True)\n",
    "        game_ids_to_fetch = game_ids_sorted[:max_games]\n",
    "        print(f\"Starting fetch for {max_games} games (newest first)...\")\n",
    "    else:\n",
    "        game_ids_to_fetch = list(game_ids)[:max_games]\n",
    "        print(f\"Starting fetch for {max_games} games...\")\n",
    "    \n",
    "    total_games = len(game_ids_to_fetch)\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    for i, game_id in enumerate(game_ids_to_fetch):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Fetching game {i+1}/{total_games}... (Success: {success_count}, Errors: {error_count})\")\n",
    "        \n",
    "        try:\n",
    "            # Ensure game_id is a string (API expects string format like \"0021501226\")\n",
    "            game_id_str = str(game_id).strip()\n",
    "            if not game_id_str or len(game_id_str) < 10:\n",
    "                raise ValueError(f\"Invalid game ID format: {game_id_str}\")\n",
    "            \n",
    "            # 1. Advanced Stats\n",
    "            adv = boxscoreadvancedv2.BoxScoreAdvancedV2(game_id=game_id_str, headers=NBA_API_HEADERS, timeout=REQUEST_TIMEOUT)\n",
    "            # Check response before calling get_data_frames()\n",
    "            try:\n",
    "                adv_frames = adv.get_data_frames()\n",
    "            except (KeyError, AttributeError) as api_err:\n",
    "                # Check if it's a resultSet error or similar API structure issue\n",
    "                if 'resultSet' in str(api_err) or 'result' in str(api_err).lower():\n",
    "                    # Try to inspect the response object\n",
    "                    if hasattr(adv, 'get_dict'):\n",
    "                        response_dict = adv.get_dict()\n",
    "                        if 'resultSets' not in response_dict or len(response_dict.get('resultSets', [])) == 0:\n",
    "                            raise ValueError(f\"API returned empty resultSets for game {game_id_str}\")\n",
    "                    raise ValueError(f\"API response structure issue for game {game_id_str}: {api_err}\")\n",
    "                raise\n",
    "            \n",
    "            # Check which dataframe has the team-level data (usually index 1, but verify)\n",
    "            if len(adv_frames) > 1:\n",
    "                adv_df = adv_frames[1]  # Team-level stats\n",
    "            elif len(adv_frames) > 0:\n",
    "                adv_df = adv_frames[0]  # Fallback to first dataframe\n",
    "            else:\n",
    "                raise ValueError(\"No dataframes returned from advanced stats API\")\n",
    "            \n",
    "            # Verify dataframe is not empty and has required columns\n",
    "            if len(adv_df) > 0 and 'GAME_ID' in adv_df.columns and 'TEAM_ID' in adv_df.columns:\n",
    "                advanced_list.append(adv_df)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid advanced stats dataframe for game {game_id_str}\")\n",
    "            \n",
    "            # 2. Four Factors\n",
    "            ff = boxscorefourfactorsv2.BoxScoreFourFactorsV2(game_id=game_id_str, headers=NBA_API_HEADERS, timeout=REQUEST_TIMEOUT)\n",
    "            # Check response before calling get_data_frames()\n",
    "            try:\n",
    "                ff_frames = ff.get_data_frames()\n",
    "            except (KeyError, AttributeError) as api_err:\n",
    "                if 'resultSet' in str(api_err) or 'result' in str(api_err).lower():\n",
    "                    if hasattr(ff, 'get_dict'):\n",
    "                        response_dict = ff.get_dict()\n",
    "                        if 'resultSets' not in response_dict or len(response_dict.get('resultSets', [])) == 0:\n",
    "                            raise ValueError(f\"API returned empty resultSets for game {game_id_str}\")\n",
    "                    raise ValueError(f\"API response structure issue for game {game_id_str}: {api_err}\")\n",
    "                raise\n",
    "            \n",
    "            # Check which dataframe has the team-level data\n",
    "            if len(ff_frames) > 1:\n",
    "                ff_df = ff_frames[1]  # Team-level stats\n",
    "            elif len(ff_frames) > 0:\n",
    "                ff_df = ff_frames[0]  # Fallback to first dataframe\n",
    "            else:\n",
    "                raise ValueError(\"No dataframes returned from four factors API\")\n",
    "            \n",
    "            # Verify dataframe is not empty and has required columns\n",
    "            if len(ff_df) > 0 and 'GAME_ID' in ff_df.columns and 'TEAM_ID' in ff_df.columns:\n",
    "                four_factors_list.append(ff_df)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid four factors dataframe for game {game_id_str}\")\n",
    "            \n",
    "            success_count += 1\n",
    "            \n",
    "            # Rate Limiting\n",
    "            time.sleep(0.6)\n",
    "            \n",
    "        except (KeyError, ValueError, AttributeError) as e:\n",
    "            # Handle API structure errors\n",
    "            error_count += 1\n",
    "            if error_count <= 5:\n",
    "                error_msg = str(e)\n",
    "                game_id_display = str(game_ids_to_fetch[i]) if i < len(game_ids_to_fetch) else \"unknown\"\n",
    "                if 'resultSet' in error_msg:\n",
    "                    print(f\"Error fetching {game_id_display}: API response structure issue - game may not exist or stats unavailable\")\n",
    "                else:\n",
    "                    print(f\"Error fetching {game_id_display}: {error_msg}\")\n",
    "            elif error_count == 6:\n",
    "                print(f\"... (suppressing further error messages)\")\n",
    "            time.sleep(1.0)\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            error_count += 1\n",
    "            if error_count <= 5:  # Only print first 5 errors to avoid spam\n",
    "                game_id_display = str(game_ids_to_fetch[i]) if i < len(game_ids_to_fetch) else \"unknown\"\n",
    "                print(f\"Error fetching {game_id_display}: {e}\")\n",
    "            elif error_count == 6:\n",
    "                print(f\"... (suppressing further error messages)\")\n",
    "            time.sleep(1.0) \n",
    "    \n",
    "    print(f\"\\nFetch complete: {success_count} successful, {error_count} errors\")\n",
    "    \n",
    "    if not advanced_list:\n",
    "        print(\"WARNING: No data was successfully fetched. Returning empty dataframes.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "        \n",
    "    return pd.concat(advanced_list, ignore_index=True), pd.concat(four_factors_list, ignore_index=True)\n",
    "\n",
    "advanced_stats, four_factors = fetch_game_details(finished_games, schedule_df=schedule_df, max_games=50, start_from_recent=True)\n",
    "print(f\"\\nAdvanced stats shape: {advanced_stats.shape}\")\n",
    "print(f\"Four factors shape: {four_factors.shape}\")\n",
    "if len(advanced_stats) > 0:\n",
    "    print(f\"\\nAdvanced stats columns: {list(advanced_stats.columns)}\")\n",
    "if len(four_factors) > 0:\n",
    "    print(f\"Four factors columns: {list(four_factors.columns)}\")\n",
    "print(\"\\nData Fetch Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6037d4bf",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "Now we merge the datasets and calculate rolling averages. **Crucially, we must group by SEASON_ID to prevent stats leaking across seasons.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(advanced_df, four_factors_df, schedule_df):\n",
    "    # Check if dataframes are empty\n",
    "    if len(advanced_df) == 0:\n",
    "        raise ValueError(\"advanced_df is empty. Check API calls.\")\n",
    "    if len(four_factors_df) == 0:\n",
    "        raise ValueError(\"four_factors_df is empty. Check API calls.\")\n",
    "    \n",
    "    # Check required columns exist\n",
    "    required_adv_cols = ['GAME_ID', 'TEAM_ID']\n",
    "    required_ff_cols = ['GAME_ID', 'TEAM_ID', 'EFG_PCT', 'TM_TOV_PCT', 'OREB_PCT', 'OPP_EFG_PCT', 'OPP_TOV_PCT', 'OPP_OREB_PCT']\n",
    "    \n",
    "    missing_adv = [col for col in required_adv_cols if col not in advanced_df.columns]\n",
    "    if missing_adv:\n",
    "        raise ValueError(f\"Missing columns in advanced_df: {missing_adv}. Available columns: {list(advanced_df.columns)}\")\n",
    "    \n",
    "    missing_ff = [col for col in required_ff_cols if col not in four_factors_df.columns]\n",
    "    if missing_ff:\n",
    "        print(f\"Warning: Missing columns in four_factors_df: {missing_ff}\")\n",
    "        print(f\"Available columns: {list(four_factors_df.columns)}\")\n",
    "        # Try to use available columns\n",
    "        available_ff_cols = [col for col in required_ff_cols if col in four_factors_df.columns]\n",
    "        available_ff_cols = ['GAME_ID', 'TEAM_ID'] + available_ff_cols[2:]  # Ensure GAME_ID and TEAM_ID are first\n",
    "        four_factors_subset = four_factors_df[available_ff_cols]\n",
    "    else:\n",
    "        four_factors_subset = four_factors_df[required_ff_cols]\n",
    "    \n",
    "    # Merge Advanced + Four Factors\n",
    "    merged_stats = pd.merge(\n",
    "        advanced_df, \n",
    "        four_factors_subset, \n",
    "        on=['GAME_ID', 'TEAM_ID'], \n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    if len(merged_stats) == 0:\n",
    "        raise ValueError(\"Merge resulted in empty dataframe. Check GAME_ID and TEAM_ID matching.\")\n",
    "    \n",
    "    # Merge with Schedule to get Dates and Matchups\n",
    "    merged_stats['GAME_ID'] = merged_stats['GAME_ID'].astype(str)\n",
    "    schedule_df['GAME_ID'] = schedule_df['GAME_ID'].astype(str)\n",
    "    \n",
    "    full_df = pd.merge(\n",
    "        merged_stats, \n",
    "        schedule_df[['GAME_ID', 'TEAM_ID', 'GAME_DATE', 'MATCHUP', 'WL', 'PLUS_MINUS', 'SEASON_ID']], \n",
    "        on=['GAME_ID', 'TEAM_ID'], \n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    if len(full_df) == 0:\n",
    "        raise ValueError(\"Final merge resulted in empty dataframe. Check GAME_ID and TEAM_ID matching with schedule.\")\n",
    "    \n",
    "    # Date Handling\n",
    "    full_df['GAME_DATE'] = pd.to_datetime(full_df['GAME_DATE'])\n",
    "    full_df = full_df.sort_values(['TEAM_ID', 'GAME_DATE'])\n",
    "    \n",
    "    print(f\"Processed {len(full_df)} game records\")\n",
    "    return full_df\n",
    "\n",
    "full_df = process_data(advanced_stats, four_factors, schedule_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15587333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rolling_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    metrics = ['OFF_RATING', 'DEF_RATING', 'NET_RATING', 'PACE', 'PIE', 'EFG_PCT', 'TM_TOV_PCT', 'OREB_PCT']\n",
    "    \n",
    "    # 1. Create Lag Features (Shift 1)\n",
    "    # Group by SEASON_ID as well to avoid cross-season leakage\n",
    "    for col in metrics:\n",
    "        df[f'PREV_{col}'] = df.groupby(['TEAM_ID', 'SEASON_ID'])[col].shift(1)\n",
    "        \n",
    "    # 2. Rolling Averages (5 and 10 games)\n",
    "    for col in metrics:\n",
    "        # Rolling 5\n",
    "        df[f'ROLLING_5_{col}'] = df.groupby(['TEAM_ID', 'SEASON_ID'])[f'PREV_{col}'].transform(lambda x: x.rolling(5).mean())\n",
    "        # Rolling 10\n",
    "        df[f'ROLLING_10_{col}'] = df.groupby(['TEAM_ID', 'SEASON_ID'])[f'PREV_{col}'].transform(lambda x: x.rolling(10).mean())\n",
    "        \n",
    "    return df\n",
    "\n",
    "rolling_df = create_rolling_features(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126fc0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_differentials(df):\n",
    "    opp_df = df.copy()\n",
    "    \n",
    "    game_merged = pd.merge(df, opp_df, on='GAME_ID', suffixes=('', '_OPP'))\n",
    "    game_merged = game_merged[game_merged['TEAM_ID'] != game_merged['TEAM_ID_OPP']]\n",
    "    \n",
    "    metrics = ['NET_RATING', 'EFG_PCT', 'TM_TOV_PCT', 'OREB_PCT']\n",
    "    windows = ['ROLLING_5', 'ROLLING_10']\n",
    "    \n",
    "    for window in windows:\n",
    "        for metric in metrics:\n",
    "            col_name = f'{window}_{metric}'\n",
    "            game_merged[f'{col_name}_DIFF'] = game_merged[col_name] - game_merged[f'{col_name}_OPP']\n",
    "            \n",
    "    return game_merged\n",
    "\n",
    "final_df = create_differentials(rolling_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba23162",
   "metadata": {},
   "source": [
    "## 4. Modeling & Backtesting\n",
    "Train on historical seasons (e.g., < 2025-26) and test on the current season (2025-26)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e70b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_backtest(df):\n",
    "    # Drop NaNs\n",
    "    df_model = df.dropna(subset=['ROLLING_5_NET_RATING_DIFF', 'PLUS_MINUS'])\n",
    "    \n",
    "    # Define Features and Target\n",
    "    features = [\n",
    "        'ROLLING_5_NET_RATING_DIFF', 'ROLLING_10_NET_RATING_DIFF',\n",
    "        'ROLLING_5_EFG_PCT_DIFF', 'ROLLING_10_EFG_PCT_DIFF',\n",
    "        'ROLLING_5_TM_TOV_PCT_DIFF', 'ROLLING_10_TM_TOV_PCT_DIFF',\n",
    "        'ROLLING_5_OREB_PCT_DIFF', 'ROLLING_10_OREB_PCT_DIFF'\n",
    "    ]\n",
    "    target_reg = 'PLUS_MINUS' # Regression target\n",
    "    target_clf = 'WL' # Classification target (W/L)\n",
    "    \n",
    "    # Convert WL to binary (W=1, L=0)\n",
    "    df_model['WL_BINARY'] = df_model['WL'].apply(lambda x: 1 if x == 'W' else 0)\n",
    "    \n",
    "    # Split Train (Past) vs Test (Current Season)\n",
    "    # Assuming '2025-26' is the current season ID format\n",
    "    current_season = '2025-26'\n",
    "    train_df = df_model[df_model['SEASON_ID'] != current_season]\n",
    "    test_df = df_model[df_model['SEASON_ID'] == current_season]\n",
    "    \n",
    "    print(f\"Training on {len(train_df)} games (Seasons < {current_season})\")\n",
    "    print(f\"Testing on {len(test_df)} games (Season == {current_season})\")\n",
    "    \n",
    "    if len(train_df) == 0 or len(test_df) == 0:\n",
    "        print(\"Insufficient data for split. Check SEASON_ID values.\")\n",
    "        return\n",
    "    \n",
    "    X_train = train_df[features]\n",
    "    y_train_reg = train_df[target_reg]\n",
    "    y_train_clf = train_df['WL_BINARY']\n",
    "    \n",
    "    X_test = test_df[features]\n",
    "    y_test_reg = test_df[target_reg]\n",
    "    y_test_clf = test_df['WL_BINARY']\n",
    "    \n",
    "    # 1. Gradient Boosting Regressor (Predict Margin)\n",
    "    gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "    gbr.fit(X_train, y_train_reg)\n",
    "    preds_reg = gbr.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_reg, preds_reg))\n",
    "    print(f\"Regressor RMSE: {rmse:.2f}\")\n",
    "    \n",
    "    # 2. Gradient Boosting Classifier (Predict Win/Loss)\n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "    gbc.fit(X_train, y_train_clf)\n",
    "    preds_clf = gbc.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test_clf, preds_clf)\n",
    "    print(f\"Classifier Accuracy: {accuracy:.2%}\")\n",
    "    print(classification_report(y_test_clf, preds_clf))\n",
    "    \n",
    "    # Feature Importance\n",
    "    feature_importance = pd.DataFrame({'Feature': features, 'Importance': gbc.feature_importances_})\n",
    "    feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "    plt.title('Feature Importance (Gradient Boosting Classifier)')\n",
    "    plt.show()\n",
    "    \n",
    "    return gbc, gbr\n",
    "\n",
    "model_clf, model_reg = train_and_backtest(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export & Storage\n",
    "Save the processed dataset for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(df, filename='final_nba_modeling_data.csv'):\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved data to {filename}\")\n",
    "\n",
    "export_data(final_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}